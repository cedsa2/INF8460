{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inf8460_projet_A20_equipe8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6984723399ad4429a78be66fead09207": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4792c5db1d1045f98440ef4ca34b433c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_30d4f585019e465a94958402d26bde1d",
              "IPY_MODEL_1d9e9b5dbe094c33a3176780ff37b9f1"
            ]
          }
        },
        "4792c5db1d1045f98440ef4ca34b433c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "30d4f585019e465a94958402d26bde1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c135251c65474c4b9d8df448cea1be6e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 473,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 473,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9ef19809a9c147ec83e5c7e94c555c9c"
          }
        },
        "1d9e9b5dbe094c33a3176780ff37b9f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_27e7045593af4d63a4c1fdd31e719c20",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 473/473 [00:00&lt;00:00, 1.53kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a6a0c7287e7b489ca1bb5d8100af8b99"
          }
        },
        "c135251c65474c4b9d8df448cea1be6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9ef19809a9c147ec83e5c7e94c555c9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "27e7045593af4d63a4c1fdd31e719c20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a6a0c7287e7b489ca1bb5d8100af8b99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "594581a8da644221a1c41a298ed4b39d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0bfa0231a34040e6b252629f85399b59",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8ac6053a92c24954b1d2e67edadebd65",
              "IPY_MODEL_a53cecd910c54965acbff9d5b1dbfc21"
            ]
          }
        },
        "0bfa0231a34040e6b252629f85399b59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8ac6053a92c24954b1d2e67edadebd65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_82c5a18e88f94fd9bc745fde8a369c27",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 260793700,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 260793700,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b01380a6701f491e8412580ad0b01262"
          }
        },
        "a53cecd910c54965acbff9d5b1dbfc21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9270001477b54b50a389f04c2406c6f4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 261M/261M [00:04&lt;00:00, 55.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bf3a5271b73f452188b40e6602771780"
          }
        },
        "82c5a18e88f94fd9bc745fde8a369c27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b01380a6701f491e8412580ad0b01262": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9270001477b54b50a389f04c2406c6f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bf3a5271b73f452188b40e6602771780": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5edaed461fdc44219061b87f71dc4957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0a6d742b0ccd4cd38f2e6510dc486b4b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b4028828b1ea4f1689e406da40bf7adb",
              "IPY_MODEL_ea8f52bc3b5f44c290833426acee4c89"
            ]
          }
        },
        "0a6d742b0ccd4cd38f2e6510dc486b4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b4028828b1ea4f1689e406da40bf7adb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_eecccd9cfb6d41a194556fee365c869c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3086765b1fb942738e2717619ebadcf7"
          }
        },
        "ea8f52bc3b5f44c290833426acee4c89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8486f5fda8b4459d97968dabfd5a4f23",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 3.19MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bef3fd3b6ff44e99829190215b0778dc"
          }
        },
        "eecccd9cfb6d41a194556fee365c869c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3086765b1fb942738e2717619ebadcf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8486f5fda8b4459d97968dabfd5a4f23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bef3fd3b6ff44e99829190215b0778dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "77fe4a29c05e447c94427d18d9aebeb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_97e283ae201e4dbdb65042da24e0594d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2c19edbf8b08457090aebf43ce972e14",
              "IPY_MODEL_3a201cc58a7d439783c14921b67f1b37"
            ]
          }
        },
        "97e283ae201e4dbdb65042da24e0594d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2c19edbf8b08457090aebf43ce972e14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c1cf65935503489fb2b7d0a6d744ed31",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 230,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 230,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_53571776f9794f34a734db33c7e2a5dd"
          }
        },
        "3a201cc58a7d439783c14921b67f1b37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a4c24addae744d1e8912ec698d2912c9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 230/230 [00:00&lt;00:00, 235B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_23b914d2eea2417986b572301325955e"
          }
        },
        "c1cf65935503489fb2b7d0a6d744ed31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "53571776f9794f34a734db33c7e2a5dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a4c24addae744d1e8912ec698d2912c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "23b914d2eea2417986b572301325955e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvon_hH2C87M"
      },
      "source": [
        "# **INF8460 A20 Project: Open-domain questions answering**\n",
        "\n",
        "<br>\n",
        "\n",
        "Equipe 8:\n",
        "\n",
        "\n",
        "*   Cedric Sadeu (Glove, ranking with classification)\n",
        "*   Mamoudou Sacko (pretraitement + TF-IDF, cosine ranking)\n",
        "*   Oumayma Messoussi (PCP Bert, ML/DL for ranking)\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMtbIoAD31sx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1b6052d-52d0-4dfe-979d-08eafa2b396a"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.5.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: tokenizers==0.9.3 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxkOcrpE4tCW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a62b6f91-bcf2-4d0a-d8a6-408161f928b1"
      },
      "source": [
        "import io\n",
        "import os\n",
        "import math\n",
        "import nltk\n",
        "import time\n",
        "import torch\n",
        "import random\n",
        "import sklearn\n",
        "import zipfile\n",
        "import operator\n",
        "import requests\n",
        "import functools\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "import multiprocessing\n",
        "from functools import partial\n",
        "from typing import Dict, List, Tuple\n",
        "from collections import Counter, defaultdict\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "from transformers import pipeline, Trainer, TrainingArguments\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, BertTokenizer, BertModel, BertForQuestionAnswering\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfLr5d9n8Nyp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b315f47d-8a1f-4ffe-8c3c-7789912159b8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls '/content/drive/My Drive/Colab Notebooks/INF8460/Project/'"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "data\t\t\t\t  LSTMSiameseTextSimilarity  yahooLTR_C14.tgz\n",
            "inf8460_projet_A20_equipe8.ipynb  output\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIcemP-_-mKa"
      },
      "source": [
        "### Lecture des donnees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSVtCiWK-_Ut"
      },
      "source": [
        "def read_data(path: str) -> Tuple[List[int], List[str]]:\n",
        "    data = pd.read_csv(path)\n",
        "    ids = data[\"id\"].tolist()\n",
        "    paragraphs = data[\"paragraph\"].tolist()\n",
        "    return ids, paragraphs\n",
        "\n",
        "def read_questions(path: str) -> Tuple[List[int], List[str], List[int], List[str]]:\n",
        "    data = pd.read_csv(path)\n",
        "    ids = data[\"id\"].tolist()\n",
        "    questions = data[\"question\"].tolist()\n",
        "    paragraph_ids = data[\"paragraph_id\"].tolist()\n",
        "    answers = data[\"answer\"].tolist()\n",
        "    return ids, questions, paragraph_ids, answers\n",
        "\n",
        "def save_to_csv(path: str, corpus):\n",
        "    df = pd.DataFrame(corpus, columns= list(corpus.keys())).head()\n",
        "    df.to_csv (os.path.join(output_path, path), index = False, header=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6h3I8Gl3769R"
      },
      "source": [
        "data_path = \"data\"\n",
        "output_path = \"/content/drive/My Drive/Colab Notebooks/INF8460/Project/output\"\n",
        "\n",
        "train_data = read_data(os.path.join(data_path, \"/content/drive/My Drive/Colab Notebooks/INF8460/Project/data/corpus.csv\"))\n",
        "train_ids = read_questions(os.path.join(data_path, \"/content/drive/My Drive/Colab Notebooks/INF8460/Project/data/train_ids.csv\"))\n",
        "\n",
        "\n",
        "paragraphs = [\" \".join(sentence.split()).lower() for sentence in train_data[1]]\n",
        "questions = [\" \".join(sentence.split()).lower() for sentence in train_ids[1]]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tj5wul4l-pMg"
      },
      "source": [
        "### Pretraitement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6Qv4veV-ojM"
      },
      "source": [
        "class Preprocess(object):\n",
        "    def __init__(self, lemmatize=True):\n",
        "        self.stopwords = set(nltk.corpus.stopwords.words(\"english\"))\n",
        "        self.lemmatize = lemmatize\n",
        "\n",
        "    def preprocess_pipeline(self, data):\n",
        "        clean_tokenized_data = self._clean_doc(data)\n",
        "        if self.lemmatize:\n",
        "            clean_tokenized_data = self._lemmatize(clean_tokenized_data)\n",
        "\n",
        "        return clean_tokenized_data\n",
        "\n",
        "    def _clean_doc(self, data):\n",
        "        tokenizer = nltk.tokenize.RegexpTokenizer(r\"\\w+\")\n",
        "        return [\n",
        "            [\n",
        "                token.lower()\n",
        "                for token in tokenizer.tokenize(review)\n",
        "                if token.lower() not in self.stopwords\n",
        "                and len(token) > 1\n",
        "                and token.isalpha()\n",
        "            ]\n",
        "            for review in data\n",
        "        ]\n",
        "\n",
        "    def _lemmatize(self, data):\n",
        "        lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "        return [[lemmatizer.lemmatize(word) for word in review] for review in data]\n",
        "\n",
        "    def convert_to_reviews(self, tokenized_reviews):\n",
        "        reviews = []\n",
        "        for tokens in tokenized_reviews:\n",
        "            reviews.append(\" \".join(tokens))\n",
        "\n",
        "        return reviews"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mybu06h-xpN"
      },
      "source": [
        "pre = Preprocess()\n",
        "\n",
        "paragraphs_tokenized = pre.preprocess_pipeline(paragraphs)\n",
        "questions_tokenized = pre.preprocess_pipeline(questions)\n",
        "\n",
        "paragraphs_text = [\" \".join(sentence) for sentence in paragraphs_tokenized]\n",
        "questions_text = [\" \".join(sentence) for sentence in questions_tokenized]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xJqabvHFNvq"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "## **1. Plongements lexicaux**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQREt5DLDV1E"
      },
      "source": [
        "### TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5mTUyWXDXj7"
      },
      "source": [
        "def buildVocab(X) -> object:\n",
        "  vectorizer = CountVectorizer(min_df=0, lowercase=False)\n",
        "  vectorizer.fit(X)\n",
        "  return vectorizer.vocabulary_\n",
        "\n",
        "def getTfIdfReprentation(vocab, data) -> object:\n",
        "  vectorizer = TfidfVectorizer(ngram_range=(1,3), vocabulary=vocab) \n",
        "  data_tfidf = vectorizer.fit_transform(data)\n",
        "  return data_tfidf"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxrCn0Nh_FFh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f10fe82a-f0bf-4821-8da0-90dc5c51921f"
      },
      "source": [
        "paragraphs_vocab = buildVocab(paragraphs_text)\n",
        "questions_vocab = buildVocab(questions_text)\n",
        "\n",
        "paragraphs_tfidf = getTfIdfReprentation(paragraphs_vocab, paragraphs_text)\n",
        "questions_tfidf = getTfIdfReprentation(questions_vocab, questions_text)\n",
        "\n",
        "print('paragraphs_tfidf:', paragraphs_tfidf.shape)\n",
        "print('questions_tfidf:', questions_tfidf.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "paragraphs_tfidf: (83327, 138070)\n",
            "questions_tfidf: (106176, 34996)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCJPGU0V_LBG"
      },
      "source": [
        "corpus = {'id': train_data[0], 'paragraph': paragraphs_tfidf }\n",
        "save_to_csv(\"corpus.csv\", corpus)\n",
        "\n",
        "train_ids = {'id': train_ids[0], 'question': paragraphs_tfidf, 'paragraph_id': train_ids[2], 'answer': train_ids[3] }\n",
        "save_to_csv(\"train_ids.csv\", train_ids)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7njiavPiDYDu"
      },
      "source": [
        "### GloVe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7TJbIqyjxHt",
        "outputId": "6e94a646-0b4e-47dc-93d2-048d20b8b0bf"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip\n",
        "!rm glove.6B.50d.txt\n",
        "!rm glove.6B.100d.txt\n",
        "!rm glove.6B.200d.txt"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-17 23:35:47--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-11-17 23:35:48--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-11-17 23:35:48--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  1.94MB/s    in 6m 28s  \n",
            "\n",
            "2020-11-17 23:42:16 (2.12 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c0c06T2DZX1"
      },
      "source": [
        "def read_from_csv(path):\n",
        "    \"\"\" \n",
        "    reads a matrix from a csv\n",
        "    \"\"\"\n",
        "    data = pd.read_csv(path)\n",
        "    data = data.dropna(axis=1,how='all')\n",
        "    return (data.to_numpy().T).tolist()\n",
        "\n",
        "def get_lines_gloves(line):\n",
        "    \"\"\" \n",
        "    this function takes:\n",
        "    line: a line from the glove text file (a string)\n",
        "    returns a tuple (word, embeddings vector)\n",
        "    \"\"\"\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    return word, np.asarray(values[1:], dtype=float)\n",
        "\n",
        "def get_gloves_dict(path = \"glove.6B.300d.txt\"):\n",
        "    \"\"\" \n",
        "    this function takes:\n",
        "    path: to a  glove text file (a string)\n",
        "    returns a dict {key=word:Value=embeddings vector}\n",
        "    \"\"\"\n",
        "    with open(path, \"r\", encoding=\"UTF-8\") as f:\n",
        "            lines = f.readlines()\n",
        "    p = multiprocessing.Pool()\n",
        "    result = p.map(get_lines_gloves, lines)\n",
        "    p.close()\n",
        "    p.join()\n",
        "    p.terminate()\n",
        "    return dict(result)\n",
        "\n",
        "def get_plong_doc(doc, embeddings_dict, len_vec_emb):\n",
        "    \"\"\"\n",
        "    this functions takes in:\n",
        "    doc: a string representing a doc in the corpus ex:'il est'\n",
        "    embeddings_dict: a dict {key=word:Value=embeddings}\n",
        "    len_vec_emb: the length of the embedding vector (d)\n",
        "    return an embedding vector for the doc \n",
        "    this result is the mean of the vector embedding of each word\n",
        "    \"\"\"\n",
        "    vectorizer = CountVectorizer()\n",
        "    temp_ = vectorizer.fit([doc]).vocabulary_\n",
        "    vec = np.zeros(len_vec_emb, dtype=float)\n",
        "    for word in temp_.keys():\n",
        "        vec += (embeddings_dict.get(word, 0) * temp_[word])\n",
        "    return vec / sum(temp_.values())\n",
        "\n",
        "def get_plong_corpus(corpus, embeddings_dict):\n",
        "    \"\"\"\n",
        "    his functions takes in:\n",
        "    corpus: ['je vais' 'il est']a list of strings representing the corpus. each string in the list is document in the corpus\n",
        "    embeddings_dict: a dict {key=word:Value=embeddings}\n",
        "    return a list of embedding vector [] each vector is the embedding vector for a doc\n",
        "    \"\"\"\n",
        "    p = multiprocessing.Pool()\n",
        "    result = p.map(partial(get_plong_doc, embeddings_dict=embeddings_dict, len_vec_emb=len(list(embeddings_dict.items())[0][1])), corpus)\n",
        "    p.close()\n",
        "    p.join()\n",
        "    p.terminate()\n",
        "    return result"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Pphx1xmi4hP"
      },
      "source": [
        "path = \"/content/drive/My Drive/Colab Notebooks/INF8460/Project/output/corpus.csv\"\n",
        "datat = read_from_csv(path)\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit(datat[1]).vocabulary_"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7JqLpSjjIJ5"
      },
      "source": [
        "glove_dict = get_gloves_dict()\n",
        "key_set = set(X.keys()) & set(glove_dict.keys())\n",
        "glove_dict_vocab_corpus = {key: glove_dict[key] for key in key_set}"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZojYC8ajNn7"
      },
      "source": [
        "plongement_doc = get_plong_corpus(datat[1], glove_dict_vocab_corpus)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDGfEFkqDaBy"
      },
      "source": [
        "### Plongements contextuels pré-entraînés / non pré-entraînés"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdpH4bcTGFd5"
      },
      "source": [
        "\n",
        "\n",
        "> #### Huggingface ready pipeline\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoAa99LV85Ug",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290,
          "referenced_widgets": [
            "6984723399ad4429a78be66fead09207",
            "4792c5db1d1045f98440ef4ca34b433c",
            "30d4f585019e465a94958402d26bde1d",
            "1d9e9b5dbe094c33a3176780ff37b9f1",
            "c135251c65474c4b9d8df448cea1be6e",
            "9ef19809a9c147ec83e5c7e94c555c9c",
            "27e7045593af4d63a4c1fdd31e719c20",
            "a6a0c7287e7b489ca1bb5d8100af8b99",
            "594581a8da644221a1c41a298ed4b39d",
            "0bfa0231a34040e6b252629f85399b59",
            "8ac6053a92c24954b1d2e67edadebd65",
            "a53cecd910c54965acbff9d5b1dbfc21",
            "82c5a18e88f94fd9bc745fde8a369c27",
            "b01380a6701f491e8412580ad0b01262",
            "9270001477b54b50a389f04c2406c6f4",
            "bf3a5271b73f452188b40e6602771780",
            "5edaed461fdc44219061b87f71dc4957",
            "0a6d742b0ccd4cd38f2e6510dc486b4b",
            "b4028828b1ea4f1689e406da40bf7adb",
            "ea8f52bc3b5f44c290833426acee4c89",
            "eecccd9cfb6d41a194556fee365c869c",
            "3086765b1fb942738e2717619ebadcf7",
            "8486f5fda8b4459d97968dabfd5a4f23",
            "bef3fd3b6ff44e99829190215b0778dc",
            "77fe4a29c05e447c94427d18d9aebeb7",
            "97e283ae201e4dbdb65042da24e0594d",
            "2c19edbf8b08457090aebf43ce972e14",
            "3a201cc58a7d439783c14921b67f1b37",
            "c1cf65935503489fb2b7d0a6d744ed31",
            "53571776f9794f34a734db33c7e2a5dd",
            "a4c24addae744d1e8912ec698d2912c9",
            "23b914d2eea2417986b572301325955e"
          ]
        },
        "outputId": "2b093b39-008d-47cc-e5f0-ca10e4b8394e"
      },
      "source": [
        "question = \"How many parameters does BERT-large have?\"\n",
        "answer_text = r\"\"\"BERT-large is really big... it has 24-layers and an embedding size of 1,024, \n",
        "                  for a total of 340M parameters! Altogether it is 1.34GB, so expect it to take \n",
        "                  a couple minutes to download to your Colab instance.\"\"\"\n",
        "\n",
        "nlp = pipeline(\"question-answering\")\n",
        "result = nlp(question=question, context=answer_text)\n",
        "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6984723399ad4429a78be66fead09207",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=473.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "594581a8da644221a1c41a298ed4b39d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=260793700.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5edaed461fdc44219061b87f71dc4957",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "77fe4a29c05e447c94427d18d9aebeb7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=230.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1374: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Answer: '340M', score: 0.7121, start: 111, end: 115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8j7a2v3hCsO"
      },
      "source": [
        "\n",
        "\n",
        "> #### DistilBERT SQuAD pre-trained\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f_V0EC6GHZ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b3a4dcf-f8ae-419d-f6aa-7c87f3be32d6"
      },
      "source": [
        "questions = [\"How many parameters does BERT-large have?\"]\n",
        "answer_text = r\"\"\"BERT-large is really big... it has 24-layers and an embedding size of 1,024, \n",
        "                  for a total of 340M parameters! Altogether it is 1.34GB, so expect it to take \n",
        "                  a couple minutes to download to your Colab instance.\"\"\"\n",
        "\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-cased-distilled-squad\", \n",
        "                                                      return_dict=True, output_hidden_states = True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased-distilled-squad\", return_dict=True)\n",
        "\n",
        "for question in questions:\n",
        "    inputs = tokenizer(question, answer_text, add_special_tokens=True, return_tensors=\"pt\")\n",
        "    input_ids = inputs[\"input_ids\"].tolist()[0]\n",
        "\n",
        "    text_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "\n",
        "    # display tokens and ids\n",
        "    for token, id in zip(text_tokens, input_ids):\n",
        "        if id == tokenizer.sep_token_id:\n",
        "            print('')\n",
        "        print('{:<12} {:>6,}'.format(token, id))\n",
        "        if id == tokenizer.sep_token_id:\n",
        "            print('')\n",
        "\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    last_hidden_states = outputs.hidden_states[-1]\n",
        "    print(last_hidden_states.shape)\n",
        "\n",
        "    answer_start = torch.argmax(outputs.start_logits)\n",
        "    answer_end = torch.argmax(outputs.end_logits) + 1\n",
        "\n",
        "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
        "\n",
        "    print(f\"Question: {question}\")\n",
        "    print(f\"Answer: {answer}, start: {answer_start}, end: {answer_end}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS]           101\n",
            "How           1,731\n",
            "many          1,242\n",
            "parameters   11,934\n",
            "does          1,674\n",
            "B               139\n",
            "##ER          9,637\n",
            "##T           1,942\n",
            "-               118\n",
            "large         1,415\n",
            "have          1,138\n",
            "?               136\n",
            "\n",
            "[SEP]           102\n",
            "\n",
            "B               139\n",
            "##ER          9,637\n",
            "##T           1,942\n",
            "-               118\n",
            "large         1,415\n",
            "is            1,110\n",
            "really        1,541\n",
            "big           1,992\n",
            ".               119\n",
            ".               119\n",
            ".               119\n",
            "it            1,122\n",
            "has           1,144\n",
            "24            1,572\n",
            "-               118\n",
            "layers        8,798\n",
            "and           1,105\n",
            "an            1,126\n",
            "em            9,712\n",
            "##bed         4,774\n",
            "##ding        3,408\n",
            "size          2,060\n",
            "of            1,104\n",
            "1               122\n",
            ",               117\n",
            "02            5,507\n",
            "##4           1,527\n",
            ",               117\n",
            "for           1,111\n",
            "a               170\n",
            "total         1,703\n",
            "of            1,104\n",
            "340          16,984\n",
            "##M           2,107\n",
            "parameters   11,934\n",
            "!               106\n",
            "Alto         17,762\n",
            "##get        16,609\n",
            "##her         4,679\n",
            "it            1,122\n",
            "is            1,110\n",
            "1               122\n",
            ".               119\n",
            "34            3,236\n",
            "##GB         13,745\n",
            ",               117\n",
            "so            1,177\n",
            "expect        5,363\n",
            "it            1,122\n",
            "to            1,106\n",
            "take          1,321\n",
            "a               170\n",
            "couple        2,337\n",
            "minutes       1,904\n",
            "to            1,106\n",
            "download      9,133\n",
            "to            1,106\n",
            "your          1,240\n",
            "Cola         17,492\n",
            "##b           1,830\n",
            "instance      5,374\n",
            ".               119\n",
            "\n",
            "[SEP]           102\n",
            "\n",
            "torch.Size([1, 76, 768])\n",
            "Question: How many parameters does BERT-large have?\n",
            "Answer: 340M, start: 45, end: 47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FEyx474lvfY"
      },
      "source": [
        "> #### BERT base pre-trained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxtmBinzK9P5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ca3b65e-be99-419a-ce3b-c59370043e0b"
      },
      "source": [
        "torch.cuda.set_device(0)\n",
        "\n",
        "questions = [\"How many parameters does BERT-large have?\"]\n",
        "answer_text = r\"\"\"BERT-large is really big... it has 24-layers and an embedding size of 1,024, \n",
        "                  for a total of 340M parameters! Altogether it is 1.34GB, so expect it to take \n",
        "                  a couple minutes to download to your Colab instance.\"\"\"\n",
        "\n",
        "model = BertModel.from_pretrained(\"bert-base-cased\", return_dict=True)\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# print(device)\n",
        "# # model = model.to(device)\n",
        "\n",
        "for question in questions:\n",
        "    inputs = tokenizer(question, return_tensors=\"pt\")\n",
        "    input_ids = inputs[\"input_ids\"].tolist()[0]\n",
        "\n",
        "    text_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "\n",
        "    # display tokens and ids\n",
        "    for token, id in zip(text_tokens, input_ids):\n",
        "        if id == tokenizer.sep_token_id:\n",
        "            print('')\n",
        "        print('{:<12} {:>6,}'.format(token, id))\n",
        "        if id == tokenizer.sep_token_id:\n",
        "            print('')\n",
        "\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    last_hidden_states = outputs.last_hidden_state\n",
        "    print(last_hidden_states.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS]           101\n",
            "How           1,731\n",
            "many          1,242\n",
            "parameters   11,934\n",
            "does          1,674\n",
            "B               139\n",
            "##ER          9,637\n",
            "##T           1,942\n",
            "-               118\n",
            "large         1,415\n",
            "have          1,138\n",
            "?               136\n",
            "\n",
            "[SEP]           102\n",
            "\n",
            "torch.Size([1, 13, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOL6YSl_l1Af"
      },
      "source": [
        "> #### DistilBERT SQuAD training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7ZSxgj2LEvb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsAA2F1kDu0P"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "## **2. Ordonnancement**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-rv-pd-D6IM"
      },
      "source": [
        "\n",
        "\n",
        "> #### cosine similarity\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFLBngxED5HE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ic4372DEFvR"
      },
      "source": [
        "\n",
        "\n",
        "> #### LambdaMART with lightgbm\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYzHFoo0d8aI"
      },
      "source": [
        "\n",
        "\n",
        "> #### LSTM Siamese text similarity\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlmWSDuwKc8K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30d32a9e-186c-44f5-e482-c661e22ae84d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYNGTM66Kufo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00310231-cc27-48f3-aa84-38727ba58d36"
      },
      "source": [
        "dpath = '/content/drive/My Drive/Colab Notebooks/INF8460/Project/'\n",
        "!ls '/content/drive/My Drive/Colab Notebooks/INF8460/Project/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data\t\t\t\t  LSTMSiameseTextSimilarity\n",
            "inf8460_projet_A20_equipe8.ipynb  yahooLTR_C14.tgz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v49V-JIeAb_"
      },
      "source": [
        "# !git clone https://github.com/amansrivastava17/lstm-siamese-text-similarity.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPuQlVrweGQD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "092c6073-4e96-4ae7-b966-7f504c3cefca"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks/INF8460/Project/LSTMSiameseTextSimilarity/')\n",
        "!wget https://github.com/brmson/dataset-sts/tree/master/data/sts/sick2014/SICK_train.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-14 22:43:07--  https://github.com/brmson/dataset-sts/tree/master/data/sts/sick2014/SICK_train.txt\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://github.com/brmson/dataset-sts/blob/master/data/sts/sick2014/SICK_train.txt [following]\n",
            "--2020-11-14 22:43:08--  https://github.com/brmson/dataset-sts/blob/master/data/sts/sick2014/SICK_train.txt\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘SICK_train.txt.1’\n",
            "\n",
            "\rSICK_train.txt.1        [<=>                 ]       0  --.-KB/s               \rSICK_train.txt.1        [ <=>                ]   1.36M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2020-11-14 22:43:08 (30.3 MB/s) - ‘SICK_train.txt.1’ saved [1430770]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Cdba8HkeeJ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "851d84e1-96c2-4f52-9d5c-585a65a9762d"
      },
      "source": [
        "from model import SiameseBiLSTM\n",
        "from inputHandler import word_embed_meta_data, create_test_data\n",
        "from config import siamese_config\n",
        "import pandas as pd\n",
        "\n",
        "############ Data Preperation ##########\n",
        "\n",
        "df = pd.read_csv('lstm-siamese-text-similarity/sample_data.csv')\n",
        "\n",
        "sentences1 = list(df['sentences1'])\n",
        "sentences2 = list(df['sentences2'])\n",
        "is_similar = list(df['is_similar'])\n",
        "del df\n",
        "\n",
        "######## Word Embedding ############\n",
        "\n",
        "tokenizer, embedding_matrix = word_embed_meta_data(sentences1 + sentences2,  siamese_config['EMBEDDING_DIM'])\n",
        "\n",
        "embedding_meta_data = {\n",
        "\t'tokenizer': tokenizer,\n",
        "\t'embedding_matrix': embedding_matrix\n",
        "}\n",
        "\n",
        "## creating sentence pairs\n",
        "sentences_pair = [(x1, x2) for x1, x2 in zip(sentences1, sentences2)]\n",
        "del sentences1\n",
        "del sentences2\n",
        "\n",
        "######## Training ########\n",
        "\n",
        "class Configuration(object):\n",
        "    \"\"\"Dump stuff here\"\"\"\n",
        "\n",
        "CONFIG = Configuration()\n",
        "\n",
        "CONFIG.embedding_dim = siamese_config['EMBEDDING_DIM']\n",
        "CONFIG.max_sequence_length = siamese_config['MAX_SEQUENCE_LENGTH']\n",
        "CONFIG.number_lstm_units = siamese_config['NUMBER_LSTM']\n",
        "CONFIG.rate_drop_lstm = siamese_config['RATE_DROP_LSTM']\n",
        "CONFIG.number_dense_units = siamese_config['NUMBER_DENSE_UNITS']\n",
        "CONFIG.activation_function = siamese_config['ACTIVATION_FUNCTION']\n",
        "CONFIG.rate_drop_dense = siamese_config['RATE_DROP_DENSE']\n",
        "CONFIG.validation_split_ratio = siamese_config['VALIDATION_SPLIT']\n",
        "\n",
        "siamese = SiameseBiLSTM(CONFIG.embedding_dim , CONFIG.max_sequence_length, CONFIG.number_lstm_units , CONFIG.number_dense_units, CONFIG.rate_drop_lstm, CONFIG.rate_drop_dense, CONFIG.activation_function, CONFIG.validation_split_ratio)\n",
        "\n",
        "best_model_path = siamese.train_model(sentences_pair, is_similar, embedding_meta_data, model_save_directory='./')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Embedding matrix shape: (3052, 50)\n",
            "Null word embeddings: 1\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/200\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 0.9770 - acc: 0.4219WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "use `tf.profiler.experimental.stop` instead.\n",
            "2/8 [======>.......................] - ETA: 3s - loss: 0.9832 - acc: 0.5000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2696s vs `on_train_batch_end` time: 0.9156s). Check your callbacks.\n",
            "8/8 [==============================] - 3s 382ms/step - loss: 0.8995 - acc: 0.5067 - val_loss: 0.7467 - val_acc: 0.3469\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 1s 149ms/step - loss: 0.8755 - acc: 0.5022 - val_loss: 0.7458 - val_acc: 0.4694\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 1s 156ms/step - loss: 0.7893 - acc: 0.5489 - val_loss: 0.7412 - val_acc: 0.4898\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 1s 141ms/step - loss: 0.7148 - acc: 0.6111 - val_loss: 0.7554 - val_acc: 0.4898\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 1s 171ms/step - loss: 0.6849 - acc: 0.6378 - val_loss: 0.7551 - val_acc: 0.4898\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 1s 152ms/step - loss: 0.7482 - acc: 0.5822 - val_loss: 0.7465 - val_acc: 0.4898\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDwJAlO1J_cw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a794331d-1eb8-4b6e-9db3-fa031c43d507"
      },
      "source": [
        "######## Testing ########\n",
        "\n",
        "from operator import itemgetter\n",
        "from keras.models import load_model\n",
        "\n",
        "model = load_model(best_model_path)\n",
        "\n",
        "test_sentence_pairs = [('What can make Physics easy to learn?','How can you make physics easy to learn?'),('How many times a day do a clocks hands overlap?','What does it mean that every time I look at the clock the numbers are the same?')]\n",
        "\n",
        "test_data_x1, test_data_x2, leaks_test = create_test_data(tokenizer,test_sentence_pairs,  siamese_config['MAX_SEQUENCE_LENGTH'])\n",
        "\n",
        "preds = list(model.predict([test_data_x1, test_data_x2, leaks_test], verbose=1).ravel())\n",
        "results = [(x, y, z) for (x, y), z in zip(test_sentence_pairs, preds)]\n",
        "results.sort(key=itemgetter(2), reverse=True)\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "[('What can make Physics easy to learn?', 'How can you make physics easy to learn?', 0.39372748), ('How many times a day do a clocks hands overlap?', 'What does it mean that every time I look at the clock the numbers are the same?', 0.169769)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrJjJW5ZOqOX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}